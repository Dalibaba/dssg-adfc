{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dce37d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from seleniumwire import webdriver\n",
    "import time\n",
    "import pathlib\n",
    "import os\n",
    "import requests\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "from io import BytesIO\n",
    "import pandas as pd\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4ea851",
   "metadata": {},
   "source": [
    "# Get metadata of all bike counting stations of a certain city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d30440e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_STUTTGART = 'https://data.eco-counter.com/ParcPublic/?id=607#'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18fb7e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get driver path\n",
    "current_path = pathlib.Path().resolve()\n",
    "driver_path = os.path.join(current_path, \"chromedriver\")\n",
    "\n",
    "driver = webdriver.Chrome(driver_path)\n",
    "\n",
    "driver.get(URL_STUTTGART)\n",
    "\n",
    "# wait for page to load competletely\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e12f3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all requests made by the page\n",
    "all_requests = driver.requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "387c1b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define target url, which shall be filtered out\n",
    "TARGET_URL = \"www.eco-visio.net\"\n",
    "GET_REQUEST = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992c34be",
   "metadata": {},
   "source": [
    "Filter out the get request made to the database and get the metadata of all bike counting stations in a city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4427aa2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.eco-visio.net/api/aladdin/1.0.0/pbl/publicwebpageplus/607?withNull=true\n"
     ]
    }
   ],
   "source": [
    "for request in all_requests:\n",
    "    # parse url and filter out query param\n",
    "    parsed_url = urlparse(request.url)\n",
    "    query_dictionary = parse_qs(parsed_url.query)\n",
    "    # check if target url matches\n",
    "    if (parsed_url.netloc == TARGET_URL):\n",
    "        GET_REQUEST = request\n",
    "        print(GET_REQUEST.url)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf29c11",
   "metadata": {},
   "source": [
    "Fetch metadata information of all counting stations of a certain city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51ec986f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_endpoint = GET_REQUEST\n",
    "response = requests.get(url_endpoint)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c1d26c",
   "metadata": {},
   "source": [
    "extract relevant metadata of the counting stations and save it to json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb3036cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_json = json.loads(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be2f9f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "counting_station_list = []\n",
    "for counting_station in data_json:\n",
    "    counting_station_dict = {}\n",
    "    counting_station_dict[\"id\"] = counting_station[\"idPdc\"]\n",
    "    counting_station_dict[\"name\"] = counting_station[\"nom\"]\n",
    "    counting_station_dict[\"latitude\"] = counting_station[\"lat\"]\n",
    "    counting_station_dict[\"longitude\"] = counting_station[\"lon\"]\n",
    "    counting_station_dict[\"start_time\"] = counting_station[\"debut\"]\n",
    "    counting_station_list.append(counting_station_dict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c00892f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "data['Stuttgart'] = counting_station_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b076ed96",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('metadata/counting_stations_metadata.json', 'w') as outfile:\n",
    "    json.dump(data, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1328d646",
   "metadata": {},
   "source": [
    "# Get data from bike counting stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d905811c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>number</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>id_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sommerda</td>\n",
       "      <td>1</td>\n",
       "      <td>51.287374</td>\n",
       "      <td>11.060599</td>\n",
       "      <td>100055269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stuttgart</td>\n",
       "      <td>1</td>\n",
       "      <td>48.784240</td>\n",
       "      <td>9.147031</td>\n",
       "      <td>100063203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stuttgart</td>\n",
       "      <td>2</td>\n",
       "      <td>48.826000</td>\n",
       "      <td>9.214880</td>\n",
       "      <td>100063205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stuttgart</td>\n",
       "      <td>3</td>\n",
       "      <td>48.716494</td>\n",
       "      <td>9.086520</td>\n",
       "      <td>100061257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stuttgart</td>\n",
       "      <td>4</td>\n",
       "      <td>48.739821</td>\n",
       "      <td>9.152228</td>\n",
       "      <td>100061633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        name number   latitude  longitude    id_list\n",
       "0   Sommerda      1  51.287374  11.060599  100055269\n",
       "1  Stuttgart      1  48.784240   9.147031  100063203\n",
       "2  Stuttgart      2  48.826000   9.214880  100063205\n",
       "3  Stuttgart      3  48.716494   9.086520  100061257\n",
       "4  Stuttgart      4  48.739821   9.152228  100061633"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metadata_counting_stations = pd.read_csv('/metadata/counting_stations_germany_metadata.csv', index_col = 0) \n",
    "df_metadata_counting_stations[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0a162e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sommerda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_row = df_metadata_counting_stations.loc[df_metadata_counting_stations['id_list'] == 100055269]\n",
    "print(df_row[\"name\"].values[0])\n",
    "df_row[\"number\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1d7664d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get ids of all stations\n",
    "counting_station_ids = list(df_metadata_counting_stations[\"id_list\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2190b358",
   "metadata": {},
   "outputs": [],
   "source": [
    "BEGIN = 20160101\n",
    "END = 20210926\n",
    "STEP = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d2d9077e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create URL for specific bike counting station\n",
    "\n",
    "def get_data_api_request(counting_station_id):\n",
    "    driver = webdriver.Chrome(driver_path)\n",
    "\n",
    "    # define target url, which shall be filtered out\n",
    "    TARGET_URL = \"www.eco-visio.net\"\n",
    "    target_get_request = \"\"\n",
    "    BASE_URL = \"https://data.eco-counter.com/public2/?id=\" +  str(counting_station_id)\n",
    "    driver.get(BASE_URL)\n",
    "    # wait for page to load competletely\n",
    "    time.sleep(1)\n",
    "\n",
    "    # get all requests made by the page\n",
    "    all_requests = driver.requests\n",
    "    \n",
    "    for request in all_requests:\n",
    "        # parse url and filter out query param\n",
    "        parsed_url = urlparse(request.url)\n",
    "        query_dictionary = parse_qs(parsed_url.query)\n",
    "        # check if target url matches and has a token in query\n",
    "        if (parsed_url.netloc == TARGET_URL and \"t\" in query_dictionary):\n",
    "            target_get_request = request\n",
    "            break\n",
    "            \n",
    "            \n",
    "    driver.close()\n",
    "    return target_get_request\n",
    "\n",
    "# Make Request and fetch the data\n",
    "    \n",
    "def create_data_api_request(get_request):\n",
    "    parsed_url = urlparse(get_request.url)\n",
    "    query_dictionary = parse_qs(parsed_url.query)\n",
    "    \n",
    "    query_dictionary = parse_qs(parsed_url.query)\n",
    "    \n",
    "    # Define Query Parameters for fetching the Data\n",
    "    \n",
    "    query_dictionary[\"begin\"] = BEGIN\n",
    "    query_dictionary[\"end\"] = END\n",
    "    query_dictionary[\"step\"] = STEP\n",
    "    \n",
    "    url_endpoint = parsed_url.scheme + \"://\" + parsed_url.netloc + parsed_url.path\n",
    "    return url_endpoint, query_dictionary\n",
    "\n",
    "# Convert fetched data stream to csv\n",
    "\n",
    "def save_data_to_csv(data_json, counting_station_id):\n",
    "    keys = data_json[0].keys()\n",
    "    date_list = []\n",
    "    comptage_list = []\n",
    "    timestamp_list = []   \n",
    "    columns = [\"date\", \"comptage\", \"timestamp\"]\n",
    "    for data_object in data_json:\n",
    "        date_list.append(data_object[\"date\"])\n",
    "        comptage_list.append(data_object[\"comptage\"])\n",
    "        timestamp_list.append(data_object[\"timestamp\"])    \n",
    "    # Calling DataFrame constructor after zipping\n",
    "    # both lists, with columns specified\n",
    "    df = pd.DataFrame(list(zip(date_list, comptage_list,timestamp_list)),\n",
    "                   columns =columns)  \n",
    "    \n",
    "    #create name\n",
    "    df_row = df_metadata_counting_stations.loc[df_metadata_counting_stations['id_list'] == counting_station_id]  \n",
    "    file_name = df_row[\"name\"].values[0] + \"_\" + df_row[\"number\"].values[0] + \".csv\"\n",
    "    \n",
    "    path = os.path.join(\"data\",file_name )\n",
    "    \n",
    "    df.to_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "10b0ca4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "found_data_list = []\n",
    "\n",
    "for counting_station_id in counting_station_ids:\n",
    "    \n",
    "    get_request = get_data_api_request(counting_station_id)\n",
    "    if get_request != \"\":\n",
    "        \n",
    "        url_endpoint, query_dictionary = create_data_api_request(get_request)\n",
    "        response = requests.get(url_endpoint, params=query_dictionary)\n",
    "        print(response)\n",
    "        \n",
    "        data_json = json.loads(response.content)\n",
    "        save_data_to_csv(data_json, counting_station_id)\n",
    "        \n",
    "        found_data_list.append(1)\n",
    "    found_data_list.append(0)        \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
